{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODIS composites and zonal stats for SOC-D \n",
    "\n",
    "\n",
    "### The following will download then average temporally through some MODIS rasters to produce the desired 5 yr May inclusive average for the SOC-D project which will be used to attribute corrine land cover polygons. \n",
    "\n",
    "The polygons are just subsets for demo purposes.\n",
    "\n",
    "### This notebook processes the monthly 1km product.\n",
    "\n",
    "It should be noted that the input rasters have already been averaged by NASA/USGS prior to the averaging below.\n",
    "\n",
    "**Please register with APPears so you can use your username and password in the workflow**\n",
    "\n",
    "https://lpdaacsvc.cr.usgs.gov/appeears/\n",
    "\n",
    "**The first part utilises a function I have written to access the APPears API to download the desired data within an AOI geojson.**\n",
    "\n",
    "**The second stacks and composites rasters then attributes the shapefiles using functions from my own lib geospatial_learn.** \n",
    "\n",
    "https://github.com/Ciaran1981/geospatial-learn\n",
    "\n",
    "The dependencies for this are numerous and it will take a long time to install SO for brevity...\n",
    "\n",
    "...rather than you having to wait, I have just provided the necessary functions locally, so provided you work in this folder you can import the function. The files are ```appears_down.py``` and ```shape.py```. This reduces our dendencies considerably.\n",
    "\n",
    "The locally based functions are imported below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.appears_down import appears_download\n",
    "from src.shape import zonal_stats\n",
    "#from geospatial_learn.shape import zonal_stats\n",
    "import src.raster as rs\n",
    "# from geospatial_learn import raster as rs\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "Data download. We use a polygon to demarcate the area of interest. To this end we have an aoi geojson ```aoi.geojson``` which is a part of Wales.\n",
    "\n",
    "We use the APPears API (functionalised for you in the file ```appears_down.py```)\n",
    "\n",
    "**Remember to register to obtain a user, password you can use with this**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the download folder\n",
    "out_dir = 'modis1km'\n",
    "os.mkdir(out_dir)\n",
    "# the vars we need for the function\n",
    "aoi = \"aoi.geojson\"\n",
    "user = 'your name'\n",
    "password='your password'\n",
    "start_date=\"05-01\"\n",
    "end_date=\"05-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use...\n",
    "```python \n",
    "appears_download?\n",
    "```\n",
    "...to query the docstring of the fuction and the params will be explained. \n",
    "\n",
    "Of most importance here are:\n",
    "```python\n",
    "product_layer=[('MOD13A3.006', '_1_km_monthly_NDVI')], recurring=True\n",
    "```\n",
    "**The products**\n",
    "\n",
    "The APPears API requires the NASA/USGS code for the product ```MOD13A3.006``` and ```_1_km_monthly_NDVI``` layer. This allows us to download subset of the product and a similar theory can be applied to Landsat bands etc.\n",
    "\n",
    "**The search**\n",
    "\n",
    "The parameters below stipulate that we are searching from start to end of May, from 2000-05 and only within the month of May. If the recurring param was switched to False we'd get all the imagery from 2000-05-01 -> 2018-05-01 rather than only within the month itself.\n",
    "\n",
    "```python \n",
    "start_date, end_date, year_range=[2011, 2015], recurring=True\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Whilst processing a repeat message will appear (pending > processing > done), followed by some joblib outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appears_download(aoi, user, password, start_date, end_date, \n",
    "                 out_dir, year_range=[2000, 2018], product_layer=[('MOD13A3.006', '_1_km_monthly_NDVI')],\n",
    "                 recurring=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Temporal composite and zonal stats\n",
    "\n",
    "It's always useful to have the whole time series so we will just filter based on the meta.\n",
    "\n",
    "The following will use the downloaded data and meta to sort through the files and weed out some errors associated with this data layer. \n",
    "\n",
    "To this end we use pandas and filter the meta data associated with the download.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apopgies - this is on the ugly side\n",
    "\n",
    "df = pd.read_csv(os.path.join(out_dir,'MOD13A3-006-Statistics.csv'))\n",
    "# change to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# get the 08-12 only images\n",
    "df1 = df.loc[(df['Date'] > \"2008-01-01\") & (df['Date'] <= \"2012-06-01\")]\n",
    "# Get the file paths\n",
    "fileList1 = [os.path.join(out_dir, f+'.tif') for f in df1[\"File Name\"]]\n",
    "# fix the file names\n",
    "fileList1 = [f.replace(\"MOD13A3_006\", \"MOD13A3.006\") for f in fileList1]\n",
    "fileList1.sort()\n",
    "\n",
    "# get the 14-18 only images\n",
    "df2 = df.loc[(df['Date'] > \"2014-01-01\") & (df['Date'] <= \"2018-06-01\")]\n",
    "# Get the file paths\n",
    "fileList2 = [os.path.join(out_dir, f+'.tif') for f in df2[\"File Name\"]]\n",
    "# fix the file names\n",
    "fileList2 = [f.replace(\"MOD13A3_006\", \"MOD13A3.006\") for f in fileList]\n",
    "fileList2.sort()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phew - finally we process rasters to composites, the steps of which are:\n",
    "\n",
    "1. Stack the layers\n",
    "2. Warp the raster to OSGB ('EPSG:27700')\n",
    "3. Calculate the depth-wise stat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2008-12\n",
    "outRas1 = os.path.join(out_dir, \"ModisMay08-12.tif\")\n",
    "rs.stack_ras(fileList1, outRas1)\n",
    "\n",
    "# warp & reproj it for later\n",
    "repro1 = outRas1[:-4]+\"espg3035.tif\"\n",
    "rs._quickwarp(outRas1, repro1, proj='EPSG:3035')\n",
    "\n",
    "# As above create the output stacks\n",
    "compRas1 = os.path.join(out_dir, \"ModisMeanMay08-12.tif\")\n",
    "\n",
    "# Finally, average through the bands \n",
    "rs.stat_comp(repro1, compRas1, bandList=[1], stat='mean')\n",
    "\n",
    "# 2014-18 - REPEAT as for above\n",
    "outRas2 = os.path.join(out_dir, \"ModisMay14-18.tif\")\n",
    "rs.stack_ras(fileList2, outRas2 )\n",
    "\n",
    "repro2 = outRas2[:-4]+\"espg3035.tif\"\n",
    "rs._quickwarp(outRas2, repro2, proj='EPSG:3035')\n",
    "\n",
    "compRas2 = os.path.join(out_dir, \"ModisMeanMay14-18.tif\")\n",
    "\n",
    "rs.stat_comp(repro2, compRas2, bandList=[1], stat='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zonal Stats\n",
    "\n",
    "Lastly we add the zonal stats using an all touching strategy. Subsets of the Corine lcm is included in the repo ```Corine12/18.gpkg```\n",
    "\n",
    "Should you wish to only include pixels not touching borders add...\n",
    "\n",
    "```python\n",
    "all_touched=False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we add the zonal stat to each polygon in corine\n",
    "inShp1 = \"corine12.gpkg\"\n",
    "inShp2 = \"corine18.gpkg\"\n",
    "\n",
    "# stats\n",
    "stats = zonal_stats(inShp1, compRas1, 1, \"May2008_15ndvi\")\n",
    "stats = zonal_stats(inShp2, compRas2, 1, \"May2014_18ndvi\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ndvi_demo]",
   "language": "python",
   "name": "conda-env-ndvi_demo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
